{
  "dataset_revision": "9fa4d0824015fe537ae2c8166781f5c79873da2c",
  "evaluation_time": 8.643924474716187,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.23",
  "scores": {
    "train": [
      {
        "accuracy": 0.595068359375,
        "ap": 0.4803375712228656,
        "f1": 0.5909410810491077,
        "hf_subset": "default",
        "languages": [
          "ind-Latn"
        ],
        "main_score": 0.5909410810491077,
        "scores_per_experiment": [
          {
            "accuracy": 0.66455078125,
            "ap": 0.5259036577557126,
            "f1": 0.6521291075488282
          },
          {
            "accuracy": 0.5634765625,
            "ap": 0.45751178780481694,
            "f1": 0.5616555898182376
          },
          {
            "accuracy": 0.56396484375,
            "ap": 0.4563865785151401,
            "f1": 0.5611851521269946
          },
          {
            "accuracy": 0.60205078125,
            "ap": 0.4890011477326627,
            "f1": 0.6019474317439005
          },
          {
            "accuracy": 0.59228515625,
            "ap": 0.4921003242065772,
            "f1": 0.5889308832837068
          },
          {
            "accuracy": 0.59375,
            "ap": 0.4732851077280125,
            "f1": 0.588093322606597
          },
          {
            "accuracy": 0.60400390625,
            "ap": 0.4903527364800623,
            "f1": 0.6038882167495532
          },
          {
            "accuracy": 0.59765625,
            "ap": 0.4824713650707405,
            "f1": 0.5966160294950051
          },
          {
            "accuracy": 0.587890625,
            "ap": 0.4630835027369711,
            "f1": 0.5741406496373385
          },
          {
            "accuracy": 0.5810546875,
            "ap": 0.4732795041979596,
            "f1": 0.580824427480916
          }
        ]
      }
    ]
  },
  "task_name": "IndonesianIdClickbaitClassification"
}